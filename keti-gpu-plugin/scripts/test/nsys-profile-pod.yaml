---
apiVersion: v1
kind: Pod
metadata:
  name: nsys-profiler
  namespace: default
  annotations:
    nvidia.com/gpumem: "8000"
    nvidia.com/gpucores: "50"
spec:
  nodeName: edge-gpu-232
  containers:
    - name: profiler
      image: nvidia/cuda:12.4.1-devel-ubuntu22.04
      command:
        - /bin/bash
        - -c
        - |
          echo "[Profiler] Ready for nsys profiling"
          echo "[Profiler] Waiting for nsys to be copied..."

          # Create workload
          cat > /tmp/workload.cu << 'CUDAEOF'
          #include <stdio.h>
          #include <cuda_runtime.h>
          #include <cublas_v2.h>
          #include <unistd.h>

          int main(int argc, char** argv) {
              const char* name = argc > 1 ? argv[1] : "A";
              int duration = argc > 2 ? atoi(argv[2]) : 10;
              const int N = 4096;
              size_t size = N * N * sizeof(float);
              float *d_A, *d_B, *d_C;

              printf("[Workload-%s] Starting %ds GPU compute...\n", name, duration);
              fflush(stdout);

              cudaMalloc(&d_A, size);
              cudaMalloc(&d_B, size);
              cudaMalloc(&d_C, size);

              float *h = (float*)malloc(size);
              for(int i = 0; i < N*N; i++) h[i] = (float)(i % 100) / 100.0f;
              cudaMemcpy(d_A, h, size, cudaMemcpyHostToDevice);
              cudaMemcpy(d_B, h, size, cudaMemcpyHostToDevice);
              free(h);

              cublasHandle_t handle;
              cublasCreate(&handle);
              float alpha = 1.0f, beta = 0.0f;

              time_t start = time(NULL);
              int iterations = 0;
              while(time(NULL) - start < duration) {
                  cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N,
                              N, N, N, &alpha, d_A, N, d_B, N, &beta, d_C, N);
                  cudaDeviceSynchronize();
                  iterations++;
              }

              printf("[Workload-%s] Done! %d iterations in %ds\n", name, iterations, duration);
              cublasDestroy(handle);
              cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);
              return 0;
          }
          CUDAEOF

          nvcc -o /tmp/workload /tmp/workload.cu -lcublas 2>&1
          echo "[Profiler] Workload compiled. Ready!"

          # Keep running
          sleep 3600
      resources:
        limits:
          nvidia.com/gpu: 1
  restartPolicy: Never
